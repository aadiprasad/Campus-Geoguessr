{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":99359,"databundleVersionId":11870477,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image\nfrom torchvision import transforms\n\nimport pandas as pd\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\n\nclass CustomDataset(Dataset):\n    def __init__(self, csv_path, img_dir, transform=None):\n        self.df = pd.read_csv(csv_path)[[\"filename\", 'Region_ID']]\n        self.img_dir = img_dir\n        self.transform = transform or transforms.ToTensor()\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_name = os.path.join(self.img_dir, self.df.iloc[idx]['filename'])\n        with Image.open(img_name) as img:\n            if self.transform:\n                img = self.transform(img)\n        label = self.df.iloc[idx]['Region_ID']\n        return img, label-1\n\n# Initialize dataset and dataloader\ntrain_csv = \"/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/labels_train.csv\"\ntrain_img_dir = \"/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/images_train/images_train/\"\n\n\nval_csv = \"/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/labels_val.csv\"\nval_img_dir = \"/kaggle/input/smai-25-sec-a-project-phase-2-region-id-prediction/images_val/images_val/\"\n\n\ntrain_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.RandomHorizontalFlip(),\n    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    # transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n    # transforms.RandomGrayscale(p=0.05),\n    # transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n    # transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    # transforms.RandomErasing(p=0.3, scale=(0.02, 0.2))\n])\n\nval_transform = transforms.Compose([  # Keep validation simple\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])\n# Initialize datasets\ntrain_dataset = CustomDataset(train_csv, train_img_dir, transform=train_transform)\nval_dataset = CustomDataset(val_csv, val_img_dir, transform=val_transform)\n\n# DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nfrom torchvision.models import convnext_base, ConvNeXt_Base_Weights\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport time\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Setup data loaders\n# Assuming train_dataset and val_dataset are already defined\n\nbatch_size=32\nnum_workers=4\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=num_workers,\n    pin_memory=True if torch.cuda.is_available() else False\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True if torch.cuda.is_available() else False\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T00:36:41.116585Z","iopub.execute_input":"2025-05-04T00:36:41.117128Z","iopub.status.idle":"2025-05-04T00:36:41.180600Z","shell.execute_reply.started":"2025-05-04T00:36:41.117103Z","shell.execute_reply":"2025-05-04T00:36:41.179862Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n\ndef build_model(num_regions):\n    # 1. Load Base model (1024-D features)\n    model = convnext_base(weights=ConvNeXt_Base_Weights.IMAGENET1K_V1)\n    \n    # 2. Ensure classifier matches Base's dimensions\n    model.classifier = nn.Sequential(\n        nn.AdaptiveAvgPool2d(1),\n        nn.Flatten(),\n        nn.LayerNorm(1024),  # ← Must be 1024 for Base\n        nn.Linear(1024, num_regions)  # ← Input dim 1024\n    )\n    return model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T00:36:43.202069Z","iopub.execute_input":"2025-05-04T00:36:43.202621Z","iopub.status.idle":"2025-05-04T00:36:43.206858Z","shell.execute_reply.started":"2025-05-04T00:36:43.202595Z","shell.execute_reply":"2025-05-04T00:36:43.206066Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Training function\ndef train_model(model, train_loader, val_loader, num_regions, num_epochs=10):\n    model = model.to(device)\n    \n    # Loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    # Use AdamW which typically works better with ConvNeXt models\n    optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.05)\n    \n    # Learning rate scheduler - reduces learning rate when validation loss plateaus\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.1, patience=2, verbose=True\n    )\n    \n    # Training metrics tracking\n    best_val_acc = 0.0\n    train_losses = []\n    val_losses = []\n    train_accs = []\n    val_accs = []\n    \n    for epoch in range(num_epochs):\n        start_time = time.time()\n        \n        # Training phase\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        train_bar = tqdm(train_loader, desc=\"Training\")\n        \n        for inputs, labels in train_bar:\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Zero the gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n            \n            # Track metrics\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            # Update progress bar\n            train_bar.set_postfix(loss=loss.item(), acc=correct/total)\n        \n        # Calculate epoch statistics\n        epoch_train_loss = running_loss / len(train_loader.dataset)\n        epoch_train_acc = 100. * correct / total\n        train_losses.append(epoch_train_loss)\n        train_accs.append(epoch_train_acc)\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            val_bar = tqdm(val_loader, desc=\"Validation\")\n            for inputs, labels in val_bar:\n                inputs, labels = inputs.to(device), labels.to(device)\n                \n                # Forward pass\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                \n                # Track metrics\n                val_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n                \n                # Update progress bar\n                val_bar.set_postfix(loss=loss.item(), acc=val_correct/val_total)\n        \n        # Calculate epoch statistics\n        epoch_val_loss = val_loss / len(val_loader.dataset)\n        epoch_val_acc = 100. * val_correct / val_total\n        val_losses.append(epoch_val_loss)\n        val_accs.append(epoch_val_acc)\n        \n        # Update learning rate based on validation loss\n        scheduler.step(epoch_val_loss)\n        \n        # Save best model\n        if epoch_val_acc > best_val_acc:\n            best_val_acc = epoch_val_acc\n            torch.save(model.state_dict(), \"/kaggle/working/best_convnext_region_classifier.pth\")\n            print(f\"New best model saved with validation accuracy: {best_val_acc:.2f}%\")\n        \n        # Print epoch summary\n        time_taken = time.time() - start_time\n        print(f\"Epoch {epoch+1}/{num_epochs} completed in {time_taken:.2f}s\")\n        print(f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%\")\n        print(f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%\")\n        print(\"-\" * 50)\n    \n    # Plot training history\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Val Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Loss Curves')\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(train_accs, label='Train Accuracy')\n    plt.plot(val_accs, label='Val Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.title('Accuracy Curves')\n    \n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.show()\n    \n    return model, train_losses, val_losses, train_accs, val_accs\n\n# Function to evaluate model on validation set\ndef evaluate_model(model, val_loader):\n    model = model.to(device)\n    model.eval()\n    \n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Calculate accuracy\n    accuracy = 100. * np.mean(np.array(all_preds) == np.array(all_labels))\n    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n    \n    # Could add more metrics like confusion matrix, per-class accuracy, etc.\n    return accuracy, all_preds, all_labels\n\n\n# Configure parameters\nbatch_size = 32\nnum_epochs = 15\n\n# Get the number of unique regions from the dataset\n# Placeholder: Replace with actual code to get num_regions\n# num_regions = len(set(train_dataset.targets))\nnum_regions = 15  # Example value, replace with actual number of regions\n\n# Build model\nmodel = build_model(num_regions)\n\n# Train model\nmodel, train_losses, val_losses, train_accs, val_accs = train_model(\n    model, train_loader, val_loader, num_regions, num_epochs\n)\n\n# Load best model\nmodel.load_state_dict(torch.load(\"best_convnext_region_classifier.pth\"), weights_only=True)\n\n# Evaluate on validation set\naccuracy, all_preds, all_labels = evaluate_model(model, val_loader)\n\nprint(f\"Final validation accuracy: {accuracy:.2f}%\")\n\n# Save the final model\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'num_regions': num_regions,\n    'accuracy': accuracy\n}, \"/kaggle/working/final_convnext_region_classifier.pth\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T00:36:44.741342Z","iopub.execute_input":"2025-05-04T00:36:44.742045Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 205/205 [05:03<00:00,  1.48s/it, acc=0.616, loss=0.599]\nValidation: 100%|██████████| 12/12 [00:03<00:00,  3.82it/s, acc=0.84, loss=0.333] \n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation accuracy: 84.01%\nEpoch 1/15 completed in 307.08s\nTrain Loss: 1.2431, Train Acc: 61.56%\nVal Loss: 0.5372, Val Acc: 84.01%\n--------------------------------------------------\nEpoch 2/15\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 205/205 [05:01<00:00,  1.47s/it, acc=0.903, loss=0.2]  \nValidation: 100%|██████████| 12/12 [00:02<00:00,  4.01it/s, acc=0.892, loss=0.208]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation accuracy: 89.16%\nEpoch 2/15 completed in 305.76s\nTrain Loss: 0.3516, Train Acc: 90.29%\nVal Loss: 0.3010, Val Acc: 89.16%\n--------------------------------------------------\nEpoch 3/15\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 205/205 [05:02<00:00,  1.47s/it, acc=0.968, loss=0.0588]\nValidation: 100%|██████████| 12/12 [00:02<00:00,  4.06it/s, acc=0.908, loss=0.0813]\n","output_type":"stream"},{"name":"stdout","text":"New best model saved with validation accuracy: 90.79%\nEpoch 3/15 completed in 305.80s\nTrain Loss: 0.1310, Train Acc: 96.76%\nVal Loss: 0.2950, Val Acc: 90.79%\n--------------------------------------------------\nEpoch 4/15\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 205/205 [05:02<00:00,  1.47s/it, acc=0.988, loss=0.0138] \nValidation:   0%|          | 0/12 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}